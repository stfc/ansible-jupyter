- name: Download the Cinder CSI Plugin
  ansible.builtin.git:
    repo: "https://github.com/kubernetes/cloud-provider-openstack.git"
    dest: "/tmp/cloud-provider-openstack"
    version: "release-1.24"
    update: true # Automatically pull bug-fixes in

- name: Install Cinder CSI
  kubernetes.core.helm:
    name: cinder-csi
    namespace: kube-system
    chart_ref: "/tmp/cloud-provider-openstack/charts/cinder-csi-plugin"

- name: Install jhub helm repo
  kubernetes.core.helm_repository:
    name: jupyterhub
    repo_url: https://jupyterhub.github.io/helm-chart/

- name: Install pre-set version of Jhub. This may take up to 25m to pull various images...
  kubernetes.core.helm:
    chart_ref: jupyterhub/jupyterhub
    create_namespace: yes
    update_repo_cache: yes
    # Pulled from default
    name: "{{ jhub_deployed_name }}"
    chart_version: "{{ jhub_version }}"
    release_namespace: "{{ jhub_namespace }}"
    values_files:
      - "{{ role_path }}/files/{{ jhub_config_file }}"
    timeout: "25m"

- name: Create namespace for Nvidia components
  kubernetes.core.k8s:
    name: "{{ item }}"
    kind: Namespace
    state: present
  with_items:
    - gpu-operator

- name: Install Nvidia GPU Operator repo
  kubernetes.core.helm_repository:
    name: nvidia
    repo_url: https://nvidia.github.io/gpu-operator

- name: Install GPU Operator, pointing to own driver
  kubernetes.core.helm:
    chart_ref: nvidia/gpu-operator
    update_repo_cache: yes
    chart_version: "1.11.0"
    name: gpu-operator
    release_namespace: gpu-operator
    release_values:
      driver:
        repository: "harbor.stfc.ac.uk/magnum_mirror"
        image: "nvidia_driver"
        version: "{{ NVIDIA_DRIVER_VERSION }}"
